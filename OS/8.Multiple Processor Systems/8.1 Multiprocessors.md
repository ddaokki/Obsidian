## Multiple Processor Systems

### 병렬 컴퓨팅의 필요성
- 클럭 속도를 더 빠르게 만드는 것은 한계에 도달함 (광속 문제)
- 해결책: **병렬 컴퓨터** (Massively Parallel Computers)
  - 수천~수백만 개의 CPU를 동시에 사용하는 구조
  - 예: 기상 예측, 유체역학 시뮬레이션, 경제 모델링, 신약 반응 모델링 등 고부하 연산에 사용

---

### 3가지 구조적 분류

#### 1. Shared-Memory Multiprocessor
- 여러 CPU가 **공통 RAM**을 공유함
- 현재 일반적인 멀티코어 CPU 구조
- **장점**: 메모리 공유가 쉬움, 프로그래밍이 간편함
- **단점**: 캐시 일관성 문제 발생 가능, 확장성 제한

#### 2. Message-Passing Multicomputer
- 각 CPU는 자신의 메모리만 접근 가능하며, 고속 링크로 통신
- 구조적으로는 단순하지만 **프로그래밍은 복잡**
- 메시지 전송 시간: 약 10~50μs

#### 3. Wide-Area Distributed System
- 인터넷 등을 통해 **독립 시스템끼리 연결**
- 통신 지연이 큼: 수십~수백 ms
- loosely coupled system이라 불리며, 클라우드 컴퓨팅 구조와 유사함

---

## 8.1 Multiprocessors

### 정의
- **Shared-memory multiprocessor**: 2개 이상의 CPU가 **공통 RAM**에 접근 가능
- 한 CPU가 쓴 데이터를 다른 CPU가 즉시 읽을 수 있음 (동기화 필요)

### OS 측면
- 멀티프로세서 OS도 일반 OS와 유사하나,
- **동기화, 리소스 관리, 스케줄링**에 차별화된 기능이 요구됨

---

## 8.1.1 Multiprocessor Hardware

### UMA (Uniform Memory Access)
- 모든 CPU가 **모든 메모리 영역에 동일한 속도**로 접근 가능
- 구조가 단순하고 프로그래밍이 쉬움

### NUMA (Non-Uniform Memory Access)
- 각 CPU가 자신의 메모리에는 빠르게, 다른 CPU 메모리에는 느리게 접근함
- 대규모 시스템에서 확장성을 위해 사용됨
- 성능 최적화를 위해 OS/컴파일러의 **메모리 위치 인식**이 필요함

## UMA Multiprocessors with Bus-Based Architectures

### (a) Single Bus 구조
- 가장 단순한 UMA 구조는 **모든 CPU와 메모리 모듈이 하나의 버스**를 공유함
- CPU는 메모리 읽기 요청 시 버스가 사용 중인지 확인하고, 대기 또는 요청 수행
- CPU 수가 많아질수록 **버스 병목 현상** 발생 → 시스템 전체 성능 저하

---

### (b) Cache 도입
- 각 CPU에 캐시를 추가하여 **메모리 접근 빈도 감소**
- 캐시는 CPU 칩 내부, 옆, 보드 위 등 다양한 위치에 배치 가능
- 캐시가 데이터를 제공하면 버스를 사용할 필요 없음 → 성능 향상

---

### 캐시 일관성 문제 (Cache Coherence)
- 캐시는 **32~64바이트 단위(cache line)**로 관리됨
- 동일 데이터가 여러 캐시에 존재할 수 있음 → 일관성 문제 발생
- 쓰기 시 다른 캐시에 쓰기 신호 발생
- 캐시 상태에 따라 discard 혹은 메모리 동기화 필요
- **MSI, MESI, MESIF** 등 캐시 일관성 프로토콜 사용

---

### (c) Private Memory 구조
- 각 CPU는 캐시 외에도 **전용 로컬 메모리**를 가지고 있음
- 공유 메모리는 공용 쓰기 데이터에만 사용
- 읽기 전용 데이터, 스택, 지역 변수 등은 **전용 메모리**에 배치
- **버스 트래픽 감소** 및 성능 향상
- 단점: 컴파일러의 적극적인 메모리 배치 협조 필요

---

## UMA Multiprocessors Using Crossbar Switches

### 버스 기반 한계
- 캐시를 써도 CPU 수가 16~32개 이상이면 **버스가 한계**
- → **Crossbar Switch**라는 별도 상호연결 네트워크가 필요

### Crossbar Switch
- n개의 CPU와 k개의 메모리를 **교차선(crosspoint)**으로 연결
- 교차점마다 스위치를 열거나 닫아 연결 여부 결정
- 동시에 여러 CPU-메모리 쌍이 독립적으로 통신 가능
- 예: (010, 000), (101, 101), (110, 010) 동시 연결

> Crossbar 구조는 확장성과 병렬성 면에서 우수하지만, **비용이 많이 들고 배선 복잡성**이 커짐

## UMA Multiprocessors Using Crossbar Switches

### 장점과 한계
- Crossbar는 모든 CPU와 메모리 모듈이 서로 직접 연결됨
- 장점: 병목이 없고 동시 접근 가능
- 단점: **교차점 수가 n²**으로 증가 → 확장성 낮음
  - 예: 1000 CPU, 1000 메모리 → 1백만 개 교차점 필요
- 중소형 시스템에서는 여전히 실용적

---

## NUMA Multiprocessors

### UMA의 확장 한계
- UMA는 싱글 버스 또는 crossbar 방식에 따라 **수십 개 수준에서 확장 한계**
- 이를 극복하기 위해 등장한 구조가 **NUMA (Non-Uniform Memory Access)**

### NUMA 특징
1. 모든 CPU가 **단일 주소 공간**을 공유함
2. 원격 메모리 접근은 LOAD/STORE로 수행됨
3. **로컬 메모리 접근은 빠르고, 원격 메모리는 느림**

---

### CC-NUMA vs NC-NUMA
- **CC-NUMA (Cache-Coherent)**: 캐시 일관성을 유지함
  - 예: 디렉터리 기반 프로토콜 사용
  - 각 캐시 라인의 위치와 상태를 빠르게 조회함
- **NC-NUMA (Non Cache-Coherent)**: 캐시 없이 메모리 접근
  - 하드웨어 비용은 줄지만, 성능 저하 가능

---

## NUMA Directory Example

### 시스템 구조
- 256개의 노드 (CPU + 16MB RAM)
- 총 메모리 2³² bytes, 64B line 기준으로 2²⁶ cache lines
- 각 노드는 2¹⁸ 개의 line에 대해 1비트씩 상태를 가짐

### 주소 분해
- 물리 주소 0x24000108 → 세 부분으로 분해됨
  - node 36, line 4, offset 8

### 디렉터리 접근 과정
1. CPU 20이 주소를 MMU를 통해 해석
2. line 4가 node 36에 있다는 사실 확인
3. node 36에 질의 → line 4가 캐시에 없는 경우 RAM에서 읽어옴
4. node 20으로 전달 후 디렉터리 업데이트

> 이러한 방식은 CC-NUMA의 캐시 일관성 유지 동작을 설명하며, 대규모 시스템에서의 성능 유지에 중요한 메커니즘임

